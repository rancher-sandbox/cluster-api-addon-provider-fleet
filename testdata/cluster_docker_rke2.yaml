apiVersion: v1
data:
  value: |-
    # generated by kind
    global
      log /dev/log local0
      log /dev/log local1 notice
      daemon
      # limit memory usage to approximately 18 MB
      # (see https://github.com/kubernetes-sigs/kind/pull/3115)
      maxconn 100000

    resolvers docker
      nameserver dns 127.0.0.11:53

    defaults
      log global
      mode tcp
      option dontlognull
      # TODO: tune these
      timeout connect 5000
      timeout client 50000
      timeout server 50000
      # allow to boot despite dns don't resolve backends
      default-server init-addr none

    frontend stats
      bind *:8404
      stats enable
      stats uri /
      stats refresh 10s

    frontend control-plane
      bind *:{{ .FrontendControlPlanePort }}
      {{ if .IPv6 -}}
      bind :::{{ .FrontendControlPlanePort }};
      {{- end }}
      default_backend kube-apiservers

    backend kube-apiservers
      option httpchk GET /healthz
      http-check expect status 401
      # TODO: we should be verifying (!)
      {{range $server, $address := .BackendServers}}
      server {{ $server }} {{ JoinHostPort $address $.BackendControlPlanePort }} check check-ssl verify none resolvers docker resolve-prefer {{ if $.IPv6 -}} ipv6 {{- else -}} ipv4 {{- end }}
      {{- end}}

    frontend rke2-join
      bind *:9345
      {{ if .IPv6 -}}
      bind :::9345;
      {{- end }}
      default_backend rke2-servers

    backend rke2-servers
      option httpchk GET /v1-rke2/readyz
      http-check expect status 403
      {{range $server, $address := .BackendServers}}
      server {{ $server }} {{ $address }}:9345 check check-ssl verify none
      {{- end}}
kind: ConfigMap
metadata:
  name: test-lb-config
  namespace: default
---
apiVersion: cluster.x-k8s.io/v1beta1
kind: Cluster
metadata:
  name: test1
  namespace: default
spec:
  clusterNetwork:
    pods:
      cidrBlocks:
      - 10.45.0.0/16
    serviceDomain: cluster.local
    services:
      cidrBlocks:
      - 10.46.0.0/16
  controlPlaneRef:
    apiVersion: controlplane.cluster.x-k8s.io/v1alpha1
    kind: RKE2ControlPlane
    name: test1-control-plane
  infrastructureRef:
    apiVersion: infrastructure.cluster.x-k8s.io/v1beta1
    kind: DockerCluster
    name: test1
---
apiVersion: infrastructure.cluster.x-k8s.io/v1beta1
kind: DockerCluster
metadata:
  name: test1
  namespace: default
spec:
  loadBalancer:
    customHAProxyConfigTemplateRef:
      name: test-lb-config
---
apiVersion: controlplane.cluster.x-k8s.io/v1alpha1
kind: RKE2ControlPlane
metadata:
  name: test1-control-plane
  namespace: default
spec:
  agentConfig:
    version: v1.31.0+rke2r1
  # nodeAnnotations:
  #   richtest: "true"
  infrastructureRef:
    apiVersion: infrastructure.cluster.x-k8s.io/v1beta1
    kind: DockerMachineTemplate
    name: controlplane
  nodeDrainTimeout: 2m
  replicas: 1
  serverConfig:
    cni: calico
---
apiVersion: infrastructure.cluster.x-k8s.io/v1beta1
kind: DockerMachineTemplate
metadata:
  name: controlplane
  namespace: default
spec:
  template:
    spec: {}
---
apiVersion: cluster.x-k8s.io/v1beta1
kind: MachineDeployment
metadata:
  name: worker-md-0
  namespace: default
spec:
  clusterName: test1
  replicas: 1
  selector:
    matchLabels:
      cluster.x-k8s.io/cluster-name: test1
  template:
    spec:
      bootstrap:
        configRef:
          apiVersion: bootstrap.cluster.x-k8s.io/v1alpha1
          kind: RKE2ConfigTemplate
          name: test1-agent
      clusterName: test1
      infrastructureRef:
        apiVersion: infrastructure.cluster.x-k8s.io/v1beta1
        kind: DockerMachineTemplate
        name: worker
      version: v1.31.0
---
apiVersion: infrastructure.cluster.x-k8s.io/v1beta1
kind: DockerMachineTemplate
metadata:
  name: worker
  namespace: default
spec:
  template:
    spec: {}
---
apiVersion: bootstrap.cluster.x-k8s.io/v1alpha1
kind: RKE2ConfigTemplate
metadata:
  name: test1-agent
  namespace: default
spec:
  template:
    spec:
      agentConfig:
        version: v1.31.0+rke2r1
      #nodeAnnotations:
      #  richtest: "true"
      # postRKE2Commands:
      # - kubectl --kubeconfig /var/lib/rancher/rke2/agent/kubelet.kubeconfig annotate node $(hostname) richtest=true
